---
title: "Handwritten Text Recognition from Crowdsourced Annotations"
collection: publications
permalink: /publication/2023-06-19-belfort
excerpt: "We explore aggregation and selection stategies to train Handwritten Text Recognition models when multiple noisy transcriptions are avaliable.<br/><img src='/images/article-2023-belfort.png'>"
date: 2023-06-18
venue: "7th International Workshop on Historical Document Imaging and Processing (HIP)"
paperurl: "https://doi.org/10.1145/3604951.3605517"
citation: "Tarride, S., Faine, T., Boillet, M., Mouchere, H., & Kermorvant, C. (2023). Handwritten Text Recognition from Crowdsourced Annotations. In Proceedings of the 7th International Workshop on Historical Document Imaging and Processing (pp. 1â€“6). Association for Computing Machinery."
---

### Keywords 
Crowdsourcing, Automatic Text Recognition (ATR).

## Abstract
In this paper, we explore different ways of training a model for handwritten text recognition when multiple imperfect or noisy transcriptions are available. We consider various training configurations, such as selecting a single transcription, retaining all transcriptions, or computing an aggregated transcription from all available annotations. In addition, we evaluate the impact of quality-based data selection, where samples with low agreement are removed from the training set. Our experiments are carried out on municipal registers of the city of Belfort (France) written between 1790 and 1946. The results show that computing a consensus transcription or training on multiple transcriptions are good alternatives. However, selecting training samples based on the degree of agreement between annotators introduces a bias in the training data and does not improve the results. Our dataset is publicly available on [Zenodo](https://zenodo.org/record/8041668).

## PDF
The PDF is available on [arXiv](https://arxiv.org/pdf/2306.10878.pdf)

