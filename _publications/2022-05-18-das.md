---
title: "A Comparative Study of Information Extraction Strategies Using an Attention-Based Neural Network"
collection: publications
permalink: /publication/2022-05-01-das
excerpt: "This paper shows the interest of multi-task attention-based networks for joint handwriting recognition and named entity extraction<br/><img src='/images/article-das.png'>"
date: 2022-05-18
venue: 'Document Analysis Systems'
paperurl: 'https://doi.org/10.1007/978-3-031-06555-2_43'
citation: 'Tarride, S., Lemaitre, A., Co√ºasnon, B., Tardivel, S. (2022). A Comparative Study of Information Extraction Strategies Using an Attention-Based Neural Network. In: Uchida, S., Barney, E., Eglin, V. (eds) Document Analysis Systems. DAS 2022. Lecture Notes in Computer Science, vol 13237. Springer, Cham.'
---

### Keywords 
Document image analysis, Historical documents, Information extraction, Handwriting recognition, Named entity recognition

### Abstract
This article focuses on information extraction in historical handwritten marriage records. Traditional approaches rely on a *sequential* pipeline of two consecutive tasks: handwriting recognition is applied before named entity recognition. More recently, *joint* approaches that handle both tasks at the same time have been investigated, yielding state-of-the-art results. However, as these approaches have been used in different experimental conditions, they have not been fairly compared yet. In this work, we conduct a comparative study of sequential and joint approaches based on the same attention-based architecture, in order to quantify the gain that can be attributed to the joint learning strategy. We also investigate three new joint learning configurations based on multi-task or multi-scale learning. Our study shows that relying on a joint learning strategy can lead to an 8% increase of the complete recognition score. We also highlight the interest of multi-task learning and demonstrate the benefit of attention-based networks for information extraction. Our work achieves state-of-the-art performance in the ICDAR 2017 Information Extraction competition on the Esposalles database at line-level, without any language model or post-processing.

### PDF
The PDF version is available on [HAL](https://hal.archives-ouvertes.fr/hal-03677908/document).